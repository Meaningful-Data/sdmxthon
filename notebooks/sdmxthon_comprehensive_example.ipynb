{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's suppose that we have some data stored in a CSV file, which correspond to a dataflow following the BIS_DER datastructure from the BIS.\n",
    "\n",
    "We can create a Dataset object in SDMXthon, and load this CSV data (ensure you have input_data.csv file in the same directory) and the related metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T16:10:05.380964900Z",
     "start_time": "2024-03-05T16:10:05.088320100Z"
    }
   },
   "outputs": [],
   "source": [
    "import sdmxthon\n",
    "from sdmxthon.model.dataset import Dataset\n",
    "\n",
    "data_instance = Dataset(unique_id='BIS:BIS_DER(1.0)', structure_type='structure')\n",
    "# Load the data from a CSV file:\n",
    "data_instance.read_csv('input_data.csv')\n",
    "\n",
    "metadata = sdmxthon.read_sdmx('https://stats.bis.org/api/v1/datastructure/BIS/BIS_DER/1.0?references=all&detail=full')\n",
    "data_instance.structure = metadata.content['DataStructures']['BIS:BIS_DER(1.0)']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SDMXthon provides a method to do a structural validation of the data against the metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T16:10:02.996034500Z",
     "start_time": "2024-03-05T16:10:02.948247Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'semantic_validation'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m validation_results \u001B[38;5;241m=\u001B[39m \u001B[43mdata_instance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msemantic_validation\u001B[49m()\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m (\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe dataset has \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(validation_results)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m errors:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m[error[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMessage\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39merror\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39mvalidation_results]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'Dataset' object has no attribute 'semantic_validation'"
     ]
    }
   ],
   "source": [
    "validation_results = data_instance.semantic_validation()\n",
    "\n",
    "print (f'The dataset has {len(validation_results)} errors:\\n {[error[\"Message\"] for error in validation_results]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the dataset is incorrect, because there are some empty values, and the dimension 'FREQ' and the mandatory attribute 'OBS_STATUS' are missing.\n",
    "It is possible to use Pandas to correct the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-05T16:10:02.978894700Z"
    }
   },
   "outputs": [],
   "source": [
    "data_instance.data['OBS_VALUE'] = data_instance.data['OBS_VALUE'].fillna(0)\n",
    "data_instance.data['FREQ'] = 'H'\n",
    "data_instance.data['OBS_STATUS'] = 'A'\n",
    "\n",
    "validation_results = data_instance.semantic_validation()\n",
    "print (f'The dataset has {len(validation_results)} errors:\\n {[error[\"Message\"] for error in validation_results]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now suppose that we want to validate that each observation is within 50% of the observation for the previous period. Again, we can use Panda's capabilities to perform these validations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-05T16:10:02.980928800Z"
    }
   },
   "outputs": [],
   "source": [
    "#Get list of dimensions excluding TIME_PERIOD:\n",
    "dimension_descriptor = data_instance.structure.dimension_descriptor.components\n",
    "dimenension_list = [key for key in dimension_descriptor]\n",
    "dimenension_list.remove('TIME_PERIOD')\n",
    "\n",
    "\n",
    "# Add a field with the previous value of the series:\n",
    "data_instance.data[\"previous_value\"] = \\\n",
    "    data_instance.data.sort_values(\"TIME_PERIOD\").groupby(dimenension_list)\\\n",
    "            [\"OBS_VALUE\"].shift(1)\n",
    "\n",
    "\n",
    "# Get if value is between the percentage of the previous value:\n",
    "data_instance.data[\"val_result\"] = data_instance.data[\"previous_value\"] / data_instance.data[\"OBS_VALUE\"]\n",
    "errors = data_instance.data[~data_instance.data[\"val_result\"].between(0.8, 1.2)].dropna()\n",
    "\n",
    "#Drop inmaterial observations (previous or current below 1000):\n",
    "errors = errors[(errors['previous_value'] > 1000) |  (errors['OBS_VALUE'] > 1000)]\n",
    "\n",
    "print(len(data_instance.data))\n",
    "print(len(errors))\n",
    "\n",
    "errors.to_csv('error.csv')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SDMXthon provides a method to simply generate an SDMX-ML message from a Dataset object.\n",
    "The message is generated as a StringIO object, but it is also possible to set a path to save the data as a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-05T16:10:02.981926500Z"
    }
   },
   "outputs": [],
   "source": [
    "data_instance.to_xml(outputPath='output_data.xml')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also make use of the FMR web service to validate the generated data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-05T16:10:02.983928800Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://127.0.0.1:8080/ws/public/data/load\"\n",
    "files = {'uploadFile': open('output_data.xml','rb')}\n",
    "\n",
    "validate_request = requests.post(url, files=files)\n",
    "\n",
    "print(validate_request.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-05T16:10:02.984925100Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "url = \"http://127.0.0.1:8080/ws/public/data/loadStatus\"\n",
    "uid =  json.loads(validate_request.text)['uid']\n",
    "\n",
    "result_request = requests.get(f'{url}?uid={uid}')\n",
    "\n",
    "result = json.loads(result_request.text)\n",
    "\n",
    "print(result['Datasets'][0]['ValidationReport'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-05T16:10:02.985925800Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdmx-nELv1vYW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
